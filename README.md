Artificial Intelligence (AI) is a branch of Science which deals with helping machines finding solutions to complex
problems in a more human-like fashion. This generally involves borrowing characteristics from human intelligence,
and applying them as algorithms in a computer friendly way.

AI Perspectives :- 
Historically, researchers have pursued several different versions of AI.
Some have defined intelligence in terms of fidelity to human performance, while others prefer an abstract, formal
definition of intelligence called rationality—loosely speaking, doing the “right thing.” The subject matter itself also
varies: some consider intelligence to be a property of internal thought processes and reasoning, while others focus
on intelligent behavior, an external characterization.
From these two dimensions—human vs. rational and thought vs. behavior, there are four possible combinations
A. Acting humanly: The Turing test approach
B. Thinking humanly: The cognitive modeling approach
C. Acting rationally: The rational agent approach
D. Thinking rationally: The “laws of thought” approach

A. Acting humanly:-
The Turing test, proposed by Alan Turing (1950), was designed as a thought experiment that would sidestep the
philosophical vagueness of the question “Can a machine think?” A computer passes the test if a human interrogator,
after posing some written questions, cannot tell whether the written responses come from a person or from a
computer.

For Machines to think, we would need
a. natural language processing to communicate successfully in a human language.
b. knowledge representation to store what it knows or hears.
c. automated reasoning to answer questions and to draw new conclusions.
d. machine learning to adapt to new circumstances and to detect and extrapolate patterns.

To pass the total Turing test, a robot will need
a. computer vision and speech recognition to perceive the world.
b. robotics to manipulate objects and move about.

B. Thinking humanly:-
  We can learn about human thought in three ways
a. introspection—trying to catch our own thoughts as they go by;
b. psychological experiments—observing a person in action;
c. brain imaging—observing the brain in action.
Once we have a sufficiently precise theory of the mind, it becomes possible to express the theory as a computer
program.

C. Acting rationally:-
The Greek philosopher Aristotle was one of the first to attempt to codify “right thinking”, their study initiated the
field called logic.
Logicians in the 19th century developed a precise notation for statements about objects in the world and the relations
among them. By 1965, programs could, in principle, solve any solvable problem described in logical notation. The so-called
logicist tradition within artificial intelligence hopes to build on such programs to create intelligent systems
The theory of probability fills this gap, allowing rigorous reasoning with uncertain information.

D. Thinking rationally:-
Agents: An agent is just something that acts. Computer agents are expected to do more: operate autonomously,
perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals.
Rational Agents: A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty,
the best expected outcome. AI has focused on the study and construction of agents that do the right thing. What counts as the right thing is
defined by the objective that we provide to the agent. This general paradigm is so pervasive that we might call it the
standard model. It prevails not only in AI, but also in control theory, where a controller minimizes a cost function; in
operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss
function; and in economics, where a decision maker maximizes utility or some measure of social welfare.

Foundation of AI
1. Philosophy :-
Aristotle (384–322 BCE) was the first to formulate a precise set of laws governing the rational part of the mind. He
developed an informal system of syllogisms for proper reasoning, which in principle allowed one to generate
conclusions mechanically, given initial premises.
Ramon Llull (c. 1232–1315) devised a system of reasoning published as Ars Magna or The Great Art (1305). Llull
tried to implement his system using an actual mechanical device: a set of paper wheels that could be rotated into
different permutations.
Around 1500, Leonardo da Vinci (1452–1519) designed but did not build a mechanical calculator; recent
reconstructions have shown the design to be functional. The first known calculating machine was constructed around
1623 by the German scientist Wilhelm Schickard (1592–1635).
Blaise Pascal (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which appear nearer to
thought than all the actions of animals.”
Gottfried Wilhelm Leibniz (1646–1716) built a mechanical device intended to carry out operations on concepts
rather than numbers, but its scope was rather limited. In his 1651 book Leviathan, Thomas Hobbes (1588–1679)
suggested the idea of a thinking machine, an “artificial animal” in his words, arguing “For what is the heart but a
spring; and the nerves, but so many strings; and the joints, but so many wheels.” He also suggested that reasoning
was like numerical computation: “For ‘reason’ ... is nothing but ‘reckoning,’ that is adding and subtracting.”
Aristotle’s algorithm was implemented 2300 years later by Newell and Simon in their General Problem Solver
program. We would now call it a greedy regression planning system (see Chapter 11 ). Methods based on logical
planning to achieve definite goals dominated the first few decades of theoretical research in AI.

2. Mathematics :-
The idea of formal logic can be traced back to the philosophers of ancient Greece, India, and China, but its
mathematical development really began with the work of George Boole (1815–1864), who worked out the details of
propositional, or Boolean, logic (Boole, 1847).
In 1879, Gottlob Frege (1848–1925) extended Boole’s logic to include objects and relations, creating the first-order
logic that is used today.
Gerolamo Cardano (1501–1576) first framed the idea of probability, describing it in terms of the possible outcomes
of gambling events.
In 1654, Blaise Pascal (1623–1662), in a letter to Pierre Fermat (1601– 1665), showed how to predict the future of an
unfinished gambling game and assign average payoffs to the gamblers

3. Economics :-
The science of economics originated in 1776, when Adam Smith (1723–1790) published An Inquiry into the Nature
and Causes of the Wealth of Nations.
Léon Walras (pronounced “Valrasse”) (1834–1910) gave utility theory a more general foundation in terms of
preferences between gambles on any outcomes (not just monetary outcomes). The theory was improved by Ramsey
(1931) and later by John von Neumann
and Oskar Morgenstern in their book The Theory of Games and
Economic Behavior (1944). Economics is no longer the study of money; rather it is the study of desires and
preferences.
Economists, with some exceptions, did not address the third question listed above: how to make rational decisions
when payoffs from actions are not immediate but instead result from several actions taken in sequence.

4. Neuroscience :-
Neuroscience is the study of the nervous system, particularly the brain.
Paul Broca’s (1824–1880) investigation of aphasia (speech deficit) in brain-damaged patients in 1861 initiated the study of
the brain’s functional organization by identifying a localized area in the left hemisphere—now called Broca’s area—that is
responsible for speech production.
By that time, it was known that the brain consisted largely of nerve cells, or neurons, but it was not until 1873 that Camillo
Golgi (1843–1926) developed a staining technique allowing the observation of individual neurons (see Figure 1.1 ).
This technique was used by Santiago Ramon y Cajal (1852–1934) in his pioneering studies of neuronal organization. It is now
widely accepted that cognitive functions result from the electrochemical operation of these structures. That is, a collection of
simple cells can lead to thought, action, and consciousness. In the pithy words of John Searle (1992), brains cause minds.

5. Psychology :-
The origins of scientific psychology are usually traced to the work of the German physicist Hermann von Helmholtz
(1821–1894) and his student Wilhelm Wundt (1832–1920).
In 1879, Wundt opened the first laboratory of experimental psychology, at the University of Leipzig.
Cognitive psychology, which views the brain as an information-processing device, can be traced back at least to
the works of William James (1842–1910). Helmholtz also insisted that perception involved a form of unconscious
logical inference. The cognitive viewpoint was largely eclipsed by behaviorism in the United States, but at
Cambridge’s Applied Psychology Unit, directed by Frederic Bartlett (1886–1969), cognitive modeling was able to
flourish.

6. Computer Engineering :-
The first operational computer was the electromechanical Heath Robinson,9 built in 1943 by Alan Turing’s team for
a single purpose: deciphering German messages.
In 1943, the same group developed the Colossus, a powerful general-purpose machine based on vacuum tubes.
The first operational programmable computer was the Z-3, the invention of Konrad Zuse in Germany in 1941. The
first electronic computer, the ABC, was assembled by John Atanasoff and his student Clifford Berry between 1940
and 1942 at Iowa State University.
We are just beginning to see hardware tuned for AI applications, such as the graphics processing unit (GPU), tensor
processing unit (TPU), and wafer scale engine (WSE). From the 1960s to about 2012, the amount of computing
power used to train top machine learning applications followed Moore’s law. A machine learning model that took a
full day to train in 2014 takes only two minutes in 2018 (Ying et al., 2018). Although it is not yet practical,
quantum computing holds out the promise of far greater accelerations for some important subclasses of AI
algorithms.

7. Control Theory :-
Ktesibios of Alexandria (c. 250 BCE) built the first self-controlling machine: a water clock with a regulator that
maintained a constant flow rate.
Modern control theory, especially the branch known as stochastic optimal control, has as its goal the design of
systems that maximize a cost function over time.
This roughly matches the standard model of AI: designing systems that behave optimally. Why, then, are AI and
control theory two different fields, despite the close connections among their founders? The answer lies in the close
coupling between the mathematical techniques that were familiar to the participants and the corresponding sets of
problems that were encompassed in each world view. Calculus and matrix algebra, the tools of control theory, lend
themselves to systems that are describable by fixed sets of continuous variables, whereas AI was founded in part as a
way to escape from these perceived limitations. The tools of logical inference and computation allowed AI
researchers to consider problems such as language, vision, and symbolic planning that fell completely outside the
control theorist’s purview.

8. Linguistics :-
In 1957, B. F. Skinner published Verbal Behavior.
the linguist Noam Chomsky, who had just published a book on his own theory, Syntactic Structures.
Modern linguistics and AI, then, were “born” at about the same time, and grew up together, intersecting in a hybrid
field called computational linguistics or natural language processing. The problem of understanding language
turned out to be considerably more complex than it seemed in 1957. Understanding language requires an
understanding of the subject matter and context, not just an understanding of the structure of sentences. This might
seem obvious, but it was not widely appreciated until the 1960s. Much of the early work in knowledge
representation (the study of how to put knowledge into a form that a computer can reason with) was tied to
language and informed by research in linguistics, which was connected in turn to decades of work on the
philosophical analysis of language.

History of AI
1. The inception of artificial intelligence (1943–1956)
2. Early enthusiasm, great expectations (1952–1969)
3. A dose of reality (1966–1973)
4. Expert systems (1969–1986)
5. The return of neural networks (1986–present)
6. Probabilistic reasoning and machine learning (1987– present)
7. Big data (2001–present)
8. Deep learning (2011–present)

The State of the Art :-
1. ROBOTIC VEHICLES(self driving cars)
2. MACHINE TRANSLATION(google)
3. SPEECH RECOGNITION(alexa,siri,cortana)
4. RECOMMENDATIONS(amazon,youtube,netflix)
5. GAME PLAYING(chess)
6. IMAGE UNDERSTANDING(captioning)
7. MEDICINE(diagnosis)
8. Risks and Benefits of AI
9. LETHAL AUTONOMOUS WEAPONS
10. SURVEILLANCE AND PERSUASION
11. BIASED DECISION MAKING
12. IMPACT ON EMPLOYMENT
13. SAFETY-CRITICAL APPLICATIONS
14. CYBERSECURITY



